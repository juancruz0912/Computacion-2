# ðŸŒ Sistema de Scraping y AnÃ¡lisis Web Distribuido

Sistema distribuido de alto rendimiento para scraping, anÃ¡lisis y procesamiento de pÃ¡ginas web utilizando Python con arquitectura cliente-servidor.

---

## ðŸ“‹ Tabla de Contenidos

- [DescripciÃ³n](#-descripciÃ³n)
- [CaracterÃ­sticas](#-caracterÃ­sticas)
- [Requisitos](#-requisitos)
- [InstalaciÃ³n](#-instalaciÃ³n)
- [Uso RÃ¡pido](#-uso-rÃ¡pido)
- [DocumentaciÃ³n Detallada](#-documentaciÃ³n-detallada)
- [SoluciÃ³n de Problemas](#SoluciÃ³n-de-problemas)
- [Estructura del Proyecto](#-estructura-del-proyecto)
- [Autor](#-autor)

---

## ðŸŽ¯ DescripciÃ³n

Este proyecto implementa un sistema distribuido que permite:

- **Scraping asÃ­ncrono** de pÃ¡ginas web sin bloquear operaciones
- **Captura de screenshots** reales usando Selenium/Chromium
- **AnÃ¡lisis de rendimiento** web (tiempos de carga, mÃ©tricas de navegaciÃ³n)
- **Procesamiento de imÃ¡genes** con generaciÃ³n de thumbnails
- **ComunicaciÃ³n eficiente** entre servidores mediante protocolo TCP custom
- **Procesamiento paralelo** usando multiprocessing

### Casos de Uso

- Monitoreo de sitios web
- AnÃ¡lisis de rendimiento de aplicaciones web
- GeneraciÃ³n de reportes de accesibilidad
- Captura automatizada de screenshots
- ExtracciÃ³n de datos estructurados

---

## âœ¨ CaracterÃ­sticas

### Servidor A (Scraping AsÃ­ncrono)
- âœ… HTTP Server con `asyncio` y `aiohttp`
- âœ… Scraping no bloqueante con `BeautifulSoup`
- âœ… ExtracciÃ³n de metadatos (Open Graph, Twitter Cards, SEO)
- âœ… Cliente TCP asÃ­ncrono para comunicaciÃ³n con Servidor B
- âœ… Rate limiting y timeouts configurables

### Servidor B (Procesamiento Distribuido)
- âœ… Pool de procesos con `multiprocessing`
- âœ… Screenshots reales con `Selenium` + `Chromium`
- âœ… AnÃ¡lisis de rendimiento web (Performance API)
- âœ… Procesamiento de imÃ¡genes asÃ­ncrono
- âœ… Manejo de mÃºltiples tareas concurrentes

### Protocolo de ComunicaciÃ³n
- âœ… SerializaciÃ³n JSON optimizada
- âœ… ValidaciÃ³n de mensajes
- âœ… Manejo robusto de errores
- âœ… Soporte para diferentes tipos de tareas

---

### Flujo de EjecuciÃ³n

```
1. Cliente â†’ HTTP GET â†’ Servidor A
2. Servidor A â†’ Scraping asÃ­ncrono (aiohttp + BeautifulSoup)
3. Servidor A â†’ TCP request â†’ Servidor B
4. Servidor B â†’ Distribuye tareas en pool de procesos:
   â”œâ”€ Worker 1: Screenshot (Selenium)
   â”œâ”€ Worker 2: Performance Analysis
   â””â”€ Worker 3: Image Processing
5. Servidor B â†’ TCP response â†’ Servidor A
6. Servidor A â†’ HTTP JSON response â†’ Cliente
```

---

## ðŸ“¦ Requisitos

### Software Requerido

```bash
# Python
Python 3.8+

# Chromium/Chrome (para screenshots)
chromium-browser >= 90.0
chromium-chromedriver >= 90.0
```

### Dependencias Python

Ver [`requirements.txt`](requirements.txt):
```
aiohttp>=3.9.0
beautifulsoup4>=4.12.0
lxml>=4.9.0
Pillow>=10.0.0
aiofiles>=23.0.0
selenium>=4.15.0
```

---

## ðŸš€ InstalaciÃ³n

### 1. Clonar el Repositorio

```bash
git clone <repository_url>
cd TP2
```

### 2. Crear Entorno Virtual

```bash
# Crear entorno virtual
python3 -m venv env

# Activar entorno virtual
# Linux/macOS:
source env/bin/activate

# Windows:
env\Scripts\activate
```

### 3. Instalar Dependencias Python

```bash
pip install --upgrade pip
pip install -r requirements.txt
```

### 4. Instalar Chromium/ChromeDriver

#### Ubuntu/Debian:
```bash
sudo apt-get update
sudo apt-get install -y chromium-browser chromium-chromedriver
```

#### macOS (con Homebrew):
```bash
brew install chromium
brew install chromedriver
```

#### Verificar instalaciÃ³n:
```bash
chromium-browser --version
chromedriver --version
```

---

## âš¡ Uso RÃ¡pido

### Inicio Manual

#### Terminal 1: Servidor B (Procesamiento)
```bash
python server_processing.py -i localhost -p 9000 -n 4
```

**ParÃ¡metros:**
- `-i, --ip`: DirecciÃ³n IP de escucha (default: localhost)
- `-p, --port`: Puerto de escucha (default: 9000)
- `-n, --processes`: NÃºmero de workers en el pool (default: nÃºcleos CPU)

#### Terminal 2: Servidor A (Scraping)
```bash
python server_scraping.py -i localhost -p 8000
```

**ParÃ¡metros:**
- `-i, --ip`: DirecciÃ³n IP de escucha (default: localhost)
- `-p, --port`: Puerto HTTP (default: 8000)
- `--processing-host`: IP del Servidor B (default: localhost)
- `--processing-port`: Puerto del Servidor B (default: 9000)

#### Terminal 3: Cliente

```bash
# Scraping bÃ¡sico (sin procesamiento)
python client.py --url https://example.com

# Scraping + Procesamiento completo
python client.py --url https://example.com --full

# Con servidor custom
python client.py --url https://example.com --server http://localhost:8000 --full
```

**ParÃ¡metros del Cliente:**
- `--url`: URL a analizar (requerido)
- `--full`: Habilitar procesamiento completo (opcional)
- `--server`: URL del Servidor A (default: http://localhost:8000)
- `--output`: Guardar resultado en archivo JSON (opcional)

---

## ðŸ“– DocumentaciÃ³n Detallada

### Endpoints del Servidor A

#### `GET /scrape`

Scraping de una URL.

**ParÃ¡metros:**
- `url` (string, requerido): URL a scrapear
- `full` (boolean, opcional): Si `true`, incluye procesamiento completo

**Ejemplo:**
```bash
curl "http://localhost:8000/scrape?url=https://example.com&full=true"
```

**Respuesta:**
```json
{
  "url": "https://example.com",
  "timestamp": "2025-11-11T20:00:00Z",
  "status": "success",
  "scraping_data": {
    "basic": {
      "title": "Example Domain",
      "text_preview": "...",
      "word_count": 25
    },
    "structure": {...},
    "links": [...],
    "images": [...],
    "metadata": {...}
  },
  "processing_data": {
    "screenshot": {...},
    "performance": {...},
    "images": {...}
  }
}
```

#### `GET /health`

Health check del servidor.

**Respuesta:**
```json
{
  "status": "healthy",
  "timestamp": "2025-11-11T20:00:00Z"
}
```

### Protocolo de ComunicaciÃ³n

El protocolo entre servidores usa TCP con mensajes length-prefixed JSON:

```
[4 bytes: length][JSON payload]
```

**Tipos de mensajes:**
- `REQUEST`: Solicitud de procesamiento
- `RESPONSE`: Respuesta exitosa
- `ERROR`: Error en procesamiento

**Tipos de tareas:**
- `SCREENSHOT`: Captura de screenshot
- `PERFORMANCE`: AnÃ¡lisis de rendimiento
- `IMAGES`: Procesamiento de imÃ¡genes
- `ALL`: Todas las tareas en paralelo

Ver [`docs/PROTOCOL.md`](docs/PROTOCOL.md) para detalles.

---


## SoluciÃ³n de problemas

### Error: "ChromeDriver not found"

```bash
# Verificar instalaciÃ³n
which chromedriver

# Si no estÃ¡ instalado
sudo apt-get install chromium-chromedriver

# Crear symlink si es necesario
sudo ln -s /usr/lib/chromium-browser/chromedriver /usr/local/bin/chromedriver
```

### Error: "Connection refused" al conectar con Servidor B

```bash
# Verificar que el Servidor B estÃ© corriendo
ps aux | grep server_processing.py

# Verificar puerto
netstat -tuln | grep 9000

# Reiniciar Servidor B
python server_processing.py -i localhost -p 9000
```

### Error: "Address already in use"

```bash
# Encontrar proceso usando el puerto
sudo lsof -i :8000
sudo lsof -i :9000

# Matar proceso
kill -9 <PID>

# O usar otro puerto
python server_scraping.py -i localhost -p 8001
```

---

## ðŸ“‚ Estructura del Proyecto

```
TP2/
â”œâ”€â”€ server_scraping.py          # Servidor A (HTTP + Scraping)
â”œâ”€â”€ server_processing.py        # Servidor B (TCP + Processing)
â”œâ”€â”€ client.py                   # Cliente CLI
â”œâ”€â”€ requirements.txt            # Dependencias Python
â”œâ”€â”€ README.md                   # Este archivo
â”œâ”€â”€ Enunciado.md                # COnsignas a cumplir del proyecto
â”‚
â”œâ”€â”€ common/                     # MÃ³dulos compartidos
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ protocol.py            # Protocolo de comunicaciÃ³n
â”‚
â”œâ”€â”€ scraper/                    # MÃ³dulo de scraping
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ web_scraper.py         # Scraper HTTP asÃ­ncrono
â”‚   â””â”€â”€ html_parser.py         # Parser HTML
â”‚
â”œâ”€â”€ processor/                  # MÃ³dulo de procesamiento
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ screenshot.py          # Generador de screenshots
â”‚   â”œâ”€â”€ performance.py         # Analizador de rendimiento
â”‚   â””â”€â”€ image_processor.py     # Procesador de imÃ¡genes
â”‚
â””â”€â”€ tests/                      # Tests
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ test_protocol.py
    â”œâ”€â”€ test_integration.py
    â””â”€â”€ test_processors.py
```

---


## ðŸ‘¥ Autor

- **Estudiante**: Juan Cruz Rupcic
- **Materia**: ComputaciÃ³n II (IngenierÃ­a InformÃ¡tica)
- **Fecha**: Noviembre 2025
- **Materia**: ComputaciÃ³n II
- **Fecha**: Noviembre 2025
---
